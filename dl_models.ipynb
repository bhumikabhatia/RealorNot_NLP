{"cells":[{"cell_type":"code","metadata":{"tags":[],"cell_id":"ae075ef2-aa43-4bdd-916d-5fc9e4eaa374","output_cleared":false},"source":"import re\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n!pip install tqdm\r\nfrom tqdm import tqdm\r\n# use tqdm with pandas\r\n# use progress_apply instead of normal apply\r\ntqdm.pandas()\r\n\r\nimport string\r\n!pip install plotly\r\npd.options.plotting.backend = \"plotly\"\r\nimport plotly.io as pio\r\nimport plotly.express as px\r\npio.templates.default = \"plotly_white\"\r\n\r\n# NLTK STUFF\r\n!pip install nltk\r\nimport nltk\r\nfrom nltk.corpus import stopwords\r\nnltk.download('stopwords')\r\nnltk.download('punkt')\r\nfrom nltk.stem.snowball import EnglishStemmer\r\nfrom nltk import word_tokenize","execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /opt/venv/lib/python3.7/site-packages (4.46.1)\n/opt/venv/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n  from pandas import Panel\nRequirement already satisfied: plotly in /opt/venv/lib/python3.7/site-packages (4.8.1)\nRequirement already satisfied: six in /opt/venv/lib/python3.7/site-packages (from plotly) (1.15.0)\nRequirement already satisfied: retrying>=1.3.3 in /opt/venv/lib/python3.7/site-packages (from plotly) (1.3.3)\nRequirement already satisfied: nltk in /opt/venv/lib/python3.7/site-packages (3.5)\nRequirement already satisfied: regex in /opt/venv/lib/python3.7/site-packages (from nltk) (2020.6.8)\nRequirement already satisfied: joblib in /opt/venv/lib/python3.7/site-packages (from nltk) (0.15.1)\nRequirement already satisfied: tqdm in /opt/venv/lib/python3.7/site-packages (from nltk) (4.46.1)\nRequirement already satisfied: click in /opt/venv/lib/python3.7/site-packages (from nltk) (7.1.2)\n[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let's import the data","metadata":{"tags":[],"cell_id":"ec7c3361-3aac-438f-9c26-7eca0099ad85"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"5d68e254-c494-49a9-94f2-b12467dbef36","output_cleared":false},"source":"sample_submission = pd.read_csv(\"/datasets/real-or-not-dataset/sample_submission.csv\")\r\ntest = pd.read_csv(\"/datasets/real-or-not-dataset/test.csv\")\r\ntrain = pd.read_csv(\"/datasets/real-or-not-dataset/train.csv\")","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"84851f04-1aa4-4348-b523-be19b43b81ae"},"source":"n = 10\r\nrandom_state = 3\r\nmodified = train\r\nmodded_test = test","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"8bf70d1a-ab5a-48c1-88b7-6153bb05a438","output_cleared":false},"source":"stop_w = stopwords.words('english')\r\nstemmer = EnglishStemmer(ignore_stopwords=True)\r\n!pip install flashgeotext\r\n# for finding the city names properly\r\nfrom flashgeotext.geotext import GeoText\r\ngeotext = GeoText(use_demo_data=True)","execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: flashgeotext in /opt/venv/lib/python3.7/site-packages (0.2.0)\nRequirement already satisfied: flashtext==2.7 in /opt/venv/lib/python3.7/site-packages (from flashgeotext) (2.7)\nRequirement already satisfied: pydantic==1.4 in /opt/venv/lib/python3.7/site-packages (from flashgeotext) (1.4)\nRequirement already satisfied: loguru==0.4.1 in /opt/venv/lib/python3.7/site-packages (from flashgeotext) (0.4.1)\n2020-06-26 11:40:14.152 | DEBUG    | flashgeotext.lookup:add:194 - cities added to pool\n2020-06-26 11:40:14.157 | DEBUG    | flashgeotext.lookup:add:194 - countries added to pool\n2020-06-26 11:40:14.158 | DEBUG    | flashgeotext.lookup:_add_demo_data:225 - demo data loaded for: ['cities', 'countries']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Process the Cols","metadata":{"tags":[],"cell_id":"24f29dfd-b42e-4aa1-a9b8-2367062b5fa9"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"c0bba98b-f461-486b-bfb3-9e88fcc96700","output_cleared":false},"source":"# Process non null keywords and locations\r\nmodified[\"keyword\"].fillna(\"\", inplace = True)\r\nmodified[\"location\"].fillna(\"\", inplace = True)\r\nmodified.sample(n=n,random_state=random_state)","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":10,"column_count":5,"columns":[{"name":"id","dtype":"int64","stats":{"unique_count":10,"nan_count":0,"min":1418,"max":10782,"histogram":[{"bin_start":1418,"bin_end":2354.4,"count":3},{"bin_start":2354.4,"bin_end":3290.8,"count":0},{"bin_start":3290.8,"bin_end":4227.2,"count":0},{"bin_start":4227.2,"bin_end":5163.6,"count":0},{"bin_start":5163.6,"bin_end":6100,"count":0},{"bin_start":6100,"bin_end":7036.4,"count":2},{"bin_start":7036.4,"bin_end":7972.8,"count":1},{"bin_start":7972.8,"bin_end":8909.2,"count":1},{"bin_start":8909.2,"bin_end":9845.6,"count":1},{"bin_start":9845.6,"bin_end":10782,"count":2}]}},{"name":"keyword","dtype":"object","stats":{"unique_count":10,"nan_count":0,"categories":[{"name":"catastrophic","count":1},{"name":"riot","count":1},{"name":"8 others","count":8}]}},{"name":"location","dtype":"object","stats":{"unique_count":10,"nan_count":0,"categories":[{"name":"Inexpressible Island ","count":1},{"name":"Los Angeles","count":1},{"name":"8 others","count":8}]}},{"name":"text","dtype":"object","stats":{"unique_count":10,"nan_count":0,"categories":[{"name":"The Catastrophic Effects of Hiroshima and Nagasaki Atomic Bombings Still Being Felt Today http://t.co/WC8AqXeDF7","count":1},{"name":"@eac4AU You can now PRE-ORDER the film on ITUNES &amp; watch 9/15!! YAY! http://t.co/fVP3Wnid4L http://t.co/bwdhIBtiKs http://t.co/qelROcI7by","count":1},{"name":"8 others","count":8}]}},{"name":"target","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":0,"max":1,"histogram":[{"bin_start":0,"bin_end":0.1,"count":4},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":6}]}}],"rows_top":{"979":{"id":1418,"keyword":"body%20bag","location":"New York","text":"genuine Leather man Bag Messenger fit iPad mini 4 tablet case cross body air jp - Full reaÛ_ http://t.co/rcBurZSb2b http://t.co/eHsfKlgRI3","target":0},"1420":{"id":2049,"keyword":"casualties","location":"Afghanistan, USA","text":"#Afghanistan: sharp rise in women and children casualties in first half of #2015 http://t.co/LdyWd4ydT9","target":1},"1506":{"id":2174,"keyword":"catastrophic","location":"Inexpressible Island ","text":"The Catastrophic Effects of Hiroshima and Nagasaki Atomic Bombings Still Being Felt Today http://t.co/WC8AqXeDF7","target":1},"4329":{"id":6148,"keyword":"hijack","location":"Nigeria","text":"Criminals Who Hijack Lorries And Buses Arrested In Enugu (PHOTO) @DONJAZZY @PoliceNG #HumanRights  https://t.co/XyFl8wy62g","target":1},"4550":{"id":6467,"keyword":"injured","location":"","text":"Washington Post - 4 dead dozens injured in Gaza blast near house leveled in summer war http://t.co/VjXa13n8Ap","target":1},"5157":{"id":7356,"keyword":"obliterate","location":"Purfleet","text":"Whereas Jez will obliterate the national debt - and give lots of new benefits - by simply printing money! Genius! https://t.co/ReffbkVG9R","target":1},"5763":{"id":8225,"keyword":"riot","location":"Los Angeles","text":"@eac4AU You can now PRE-ORDER the film on ITUNES &amp; watch 9/15!! YAY! http://t.co/fVP3Wnid4L http://t.co/bwdhIBtiKs http://t.co/qelROcI7by","target":0},"6671":{"id":9562,"keyword":"thunder","location":"Atlanta, GA","text":"Am I hearing thunder or trucks?","target":0},"6984":{"id":10016,"keyword":"twister","location":"Detroit","text":"Crazy Mom Threw Teen Daughter a NUDE Twister Sex Party According To Her Friend59 more pics http://t.co/t94LNfwf34 http://t.co/roCyyEI2dM","target":0},"7541":{"id":10782,"keyword":"wreckage","location":"New Delhi,India","text":"Wreckage 'Conclusively Confirmed' as From MH370: Malaysia PM: Investigators and the families of those who were... http://t.co/1YIxFG1Hdy","target":1}},"rows_bottom":null},"text/plain":"         id       keyword               location  \\\n1506   2174  catastrophic  Inexpressible Island    \n5763   8225          riot            Los Angeles   \n5157   7356    obliterate               Purfleet   \n4550   6467       injured                          \n4329   6148        hijack                Nigeria   \n1420   2049    casualties       Afghanistan, USA   \n6984  10016       twister                Detroit   \n7541  10782      wreckage        New Delhi,India   \n979    1418    body%20bag               New York   \n6671   9562       thunder            Atlanta, GA   \n\n                                                   text  target  \n1506  The Catastrophic Effects of Hiroshima and Naga...       1  \n5763  @eac4AU You can now PRE-ORDER the film on ITUN...       0  \n5157  Whereas Jez will obliterate the national debt ...       1  \n4550  Washington Post - 4 dead dozens injured in Gaz...       1  \n4329  Criminals Who Hijack Lorries And Buses Arreste...       1  \n1420  #Afghanistan: sharp rise in women and children...       1  \n6984  Crazy Mom Threw Teen Daughter a NUDE Twister S...       0  \n7541  Wreckage 'Conclusively Confirmed' as From MH37...       1  \n979   genuine Leather man Bag Messenger fit iPad min...       0  \n6671                    Am I hearing thunder or trucks?       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1506</th>\n      <td>2174</td>\n      <td>catastrophic</td>\n      <td>Inexpressible Island</td>\n      <td>The Catastrophic Effects of Hiroshima and Naga...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5763</th>\n      <td>8225</td>\n      <td>riot</td>\n      <td>Los Angeles</td>\n      <td>@eac4AU You can now PRE-ORDER the film on ITUN...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5157</th>\n      <td>7356</td>\n      <td>obliterate</td>\n      <td>Purfleet</td>\n      <td>Whereas Jez will obliterate the national debt ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4550</th>\n      <td>6467</td>\n      <td>injured</td>\n      <td></td>\n      <td>Washington Post - 4 dead dozens injured in Gaz...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4329</th>\n      <td>6148</td>\n      <td>hijack</td>\n      <td>Nigeria</td>\n      <td>Criminals Who Hijack Lorries And Buses Arreste...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1420</th>\n      <td>2049</td>\n      <td>casualties</td>\n      <td>Afghanistan, USA</td>\n      <td>#Afghanistan: sharp rise in women and children...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6984</th>\n      <td>10016</td>\n      <td>twister</td>\n      <td>Detroit</td>\n      <td>Crazy Mom Threw Teen Daughter a NUDE Twister S...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7541</th>\n      <td>10782</td>\n      <td>wreckage</td>\n      <td>New Delhi,India</td>\n      <td>Wreckage 'Conclusively Confirmed' as From MH37...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>979</th>\n      <td>1418</td>\n      <td>body%20bag</td>\n      <td>New York</td>\n      <td>genuine Leather man Bag Messenger fit iPad min...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6671</th>\n      <td>9562</td>\n      <td>thunder</td>\n      <td>Atlanta, GA</td>\n      <td>Am I hearing thunder or trucks?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"02a93f63-7420-46a3-937c-b69084913ed8","output_cleared":false},"source":"def makecountryarray(x):\r\n    countries = geotext.extract(input_text=str(x), span_info=False)['countries']\r\n    country = \"\"\r\n    for items in countries:\r\n        country =  country + ' ' + items\r\n    # print(\"location : {}, got {}\".format(x, country))\r\n    return country\r\nprint(makecountryarray(\"I'd like to build a wall between Mexico and Usa\"))","execution_count":null,"outputs":[{"name":"stdout","text":" Mexico United States\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"a96c4f6d-d0a3-4e15-a63a-efc2c4fb59ad","output_cleared":false},"source":"# Convert the weird location to a more standardized tag\r\nmodified.location = modified.location.progress_apply(makecountryarray)","execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 7613/7613 [00:00<00:00, 102437.94it/s]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"d27b08f7-b932-40ef-89fe-982a254c3a05","output_cleared":false},"source":"modified.sample(n=n,random_state=random_state)","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":10,"column_count":5,"columns":[{"name":"id","dtype":"int64","stats":{"unique_count":10,"nan_count":0,"min":1418,"max":10782,"histogram":[{"bin_start":1418,"bin_end":2354.4,"count":3},{"bin_start":2354.4,"bin_end":3290.8,"count":0},{"bin_start":3290.8,"bin_end":4227.2,"count":0},{"bin_start":4227.2,"bin_end":5163.6,"count":0},{"bin_start":5163.6,"bin_end":6100,"count":0},{"bin_start":6100,"bin_end":7036.4,"count":2},{"bin_start":7036.4,"bin_end":7972.8,"count":1},{"bin_start":7972.8,"bin_end":8909.2,"count":1},{"bin_start":8909.2,"bin_end":9845.6,"count":1},{"bin_start":9845.6,"bin_end":10782,"count":2}]}},{"name":"keyword","dtype":"object","stats":{"unique_count":10,"nan_count":0,"categories":[{"name":"catastrophic","count":1},{"name":"riot","count":1},{"name":"8 others","count":8}]}},{"name":"location","dtype":"object","stats":{"unique_count":3,"nan_count":0,"categories":[{"name":"","count":8},{"name":" Afghanistan United States","count":1},{"name":" India","count":1}]}},{"name":"text","dtype":"object","stats":{"unique_count":10,"nan_count":0,"categories":[{"name":"The Catastrophic Effects of Hiroshima and Nagasaki Atomic Bombings Still Being Felt Today http://t.co/WC8AqXeDF7","count":1},{"name":"@eac4AU You can now PRE-ORDER the film on ITUNES &amp; watch 9/15!! YAY! http://t.co/fVP3Wnid4L http://t.co/bwdhIBtiKs http://t.co/qelROcI7by","count":1},{"name":"8 others","count":8}]}},{"name":"target","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":0,"max":1,"histogram":[{"bin_start":0,"bin_end":0.1,"count":4},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":6}]}}],"rows_top":{"979":{"id":1418,"keyword":"body%20bag","location":"","text":"genuine Leather man Bag Messenger fit iPad mini 4 tablet case cross body air jp - Full reaÛ_ http://t.co/rcBurZSb2b http://t.co/eHsfKlgRI3","target":0},"1420":{"id":2049,"keyword":"casualties","location":" Afghanistan United States","text":"#Afghanistan: sharp rise in women and children casualties in first half of #2015 http://t.co/LdyWd4ydT9","target":1},"1506":{"id":2174,"keyword":"catastrophic","location":"","text":"The Catastrophic Effects of Hiroshima and Nagasaki Atomic Bombings Still Being Felt Today http://t.co/WC8AqXeDF7","target":1},"4329":{"id":6148,"keyword":"hijack","location":"","text":"Criminals Who Hijack Lorries And Buses Arrested In Enugu (PHOTO) @DONJAZZY @PoliceNG #HumanRights  https://t.co/XyFl8wy62g","target":1},"4550":{"id":6467,"keyword":"injured","location":"","text":"Washington Post - 4 dead dozens injured in Gaza blast near house leveled in summer war http://t.co/VjXa13n8Ap","target":1},"5157":{"id":7356,"keyword":"obliterate","location":"","text":"Whereas Jez will obliterate the national debt - and give lots of new benefits - by simply printing money! Genius! https://t.co/ReffbkVG9R","target":1},"5763":{"id":8225,"keyword":"riot","location":"","text":"@eac4AU You can now PRE-ORDER the film on ITUNES &amp; watch 9/15!! YAY! http://t.co/fVP3Wnid4L http://t.co/bwdhIBtiKs http://t.co/qelROcI7by","target":0},"6671":{"id":9562,"keyword":"thunder","location":"","text":"Am I hearing thunder or trucks?","target":0},"6984":{"id":10016,"keyword":"twister","location":"","text":"Crazy Mom Threw Teen Daughter a NUDE Twister Sex Party According To Her Friend59 more pics http://t.co/t94LNfwf34 http://t.co/roCyyEI2dM","target":0},"7541":{"id":10782,"keyword":"wreckage","location":" India","text":"Wreckage 'Conclusively Confirmed' as From MH370: Malaysia PM: Investigators and the families of those who were... http://t.co/1YIxFG1Hdy","target":1}},"rows_bottom":null},"text/plain":"         id       keyword                    location  \\\n1506   2174  catastrophic                               \n5763   8225          riot                               \n5157   7356    obliterate                               \n4550   6467       injured                               \n4329   6148        hijack                               \n1420   2049    casualties   Afghanistan United States   \n6984  10016       twister                               \n7541  10782      wreckage                       India   \n979    1418    body%20bag                               \n6671   9562       thunder                               \n\n                                                   text  target  \n1506  The Catastrophic Effects of Hiroshima and Naga...       1  \n5763  @eac4AU You can now PRE-ORDER the film on ITUN...       0  \n5157  Whereas Jez will obliterate the national debt ...       1  \n4550  Washington Post - 4 dead dozens injured in Gaz...       1  \n4329  Criminals Who Hijack Lorries And Buses Arreste...       1  \n1420  #Afghanistan: sharp rise in women and children...       1  \n6984  Crazy Mom Threw Teen Daughter a NUDE Twister S...       0  \n7541  Wreckage 'Conclusively Confirmed' as From MH37...       1  \n979   genuine Leather man Bag Messenger fit iPad min...       0  \n6671                    Am I hearing thunder or trucks?       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1506</th>\n      <td>2174</td>\n      <td>catastrophic</td>\n      <td></td>\n      <td>The Catastrophic Effects of Hiroshima and Naga...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5763</th>\n      <td>8225</td>\n      <td>riot</td>\n      <td></td>\n      <td>@eac4AU You can now PRE-ORDER the film on ITUN...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5157</th>\n      <td>7356</td>\n      <td>obliterate</td>\n      <td></td>\n      <td>Whereas Jez will obliterate the national debt ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4550</th>\n      <td>6467</td>\n      <td>injured</td>\n      <td></td>\n      <td>Washington Post - 4 dead dozens injured in Gaz...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4329</th>\n      <td>6148</td>\n      <td>hijack</td>\n      <td></td>\n      <td>Criminals Who Hijack Lorries And Buses Arreste...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1420</th>\n      <td>2049</td>\n      <td>casualties</td>\n      <td>Afghanistan United States</td>\n      <td>#Afghanistan: sharp rise in women and children...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6984</th>\n      <td>10016</td>\n      <td>twister</td>\n      <td></td>\n      <td>Crazy Mom Threw Teen Daughter a NUDE Twister S...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7541</th>\n      <td>10782</td>\n      <td>wreckage</td>\n      <td>India</td>\n      <td>Wreckage 'Conclusively Confirmed' as From MH37...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>979</th>\n      <td>1418</td>\n      <td>body%20bag</td>\n      <td></td>\n      <td>genuine Leather man Bag Messenger fit iPad min...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6671</th>\n      <td>9562</td>\n      <td>thunder</td>\n      <td></td>\n      <td>Am I hearing thunder or trucks?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"344c6f5a-6cea-4cbb-a951-7f62177f38ab","output_cleared":false},"source":"def vectandstem(x):\r\n    tokenized = word_tokenize(str(x))\r\n    \r\n    full= \" \".join(tokenized)\r\n    return full\r\n\r\nprint(vectandstem(\"emergencies totally\"))","execution_count":null,"outputs":[{"name":"stdout","text":"emergencies totally\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"1381784a-8e82-4d4b-a03b-885411d6cc69","output_cleared":false},"source":"# Vectorize and stem the keywords\r\nmodified.keyword = modified.keyword.progress_apply(vectandstem)","execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 7613/7613 [00:00<00:00, 11388.20it/s]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"4113effc-908e-4797-9f57-29bd9fbb8d8c","output_cleared":false},"source":"modified.sample(n=n,random_state=random_state)","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":10,"column_count":5,"columns":[{"name":"id","dtype":"int64","stats":{"unique_count":10,"nan_count":0,"min":1418,"max":10782,"histogram":[{"bin_start":1418,"bin_end":2354.4,"count":3},{"bin_start":2354.4,"bin_end":3290.8,"count":0},{"bin_start":3290.8,"bin_end":4227.2,"count":0},{"bin_start":4227.2,"bin_end":5163.6,"count":0},{"bin_start":5163.6,"bin_end":6100,"count":0},{"bin_start":6100,"bin_end":7036.4,"count":2},{"bin_start":7036.4,"bin_end":7972.8,"count":1},{"bin_start":7972.8,"bin_end":8909.2,"count":1},{"bin_start":8909.2,"bin_end":9845.6,"count":1},{"bin_start":9845.6,"bin_end":10782,"count":2}]}},{"name":"keyword","dtype":"object","stats":{"unique_count":10,"nan_count":0,"categories":[{"name":"catastrophic","count":1},{"name":"riot","count":1},{"name":"8 others","count":8}]}},{"name":"location","dtype":"object","stats":{"unique_count":3,"nan_count":0,"categories":[{"name":"","count":8},{"name":" Afghanistan United States","count":1},{"name":" India","count":1}]}},{"name":"text","dtype":"object","stats":{"unique_count":10,"nan_count":0,"categories":[{"name":"The Catastrophic Effects of Hiroshima and Nagasaki Atomic Bombings Still Being Felt Today http://t.co/WC8AqXeDF7","count":1},{"name":"@eac4AU You can now PRE-ORDER the film on ITUNES &amp; watch 9/15!! YAY! http://t.co/fVP3Wnid4L http://t.co/bwdhIBtiKs http://t.co/qelROcI7by","count":1},{"name":"8 others","count":8}]}},{"name":"target","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":0,"max":1,"histogram":[{"bin_start":0,"bin_end":0.1,"count":4},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":6}]}}],"rows_top":{"979":{"id":1418,"keyword":"body % 20bag","location":"","text":"genuine Leather man Bag Messenger fit iPad mini 4 tablet case cross body air jp - Full reaÛ_ http://t.co/rcBurZSb2b http://t.co/eHsfKlgRI3","target":0},"1420":{"id":2049,"keyword":"casualties","location":" Afghanistan United States","text":"#Afghanistan: sharp rise in women and children casualties in first half of #2015 http://t.co/LdyWd4ydT9","target":1},"1506":{"id":2174,"keyword":"catastrophic","location":"","text":"The Catastrophic Effects of Hiroshima and Nagasaki Atomic Bombings Still Being Felt Today http://t.co/WC8AqXeDF7","target":1},"4329":{"id":6148,"keyword":"hijack","location":"","text":"Criminals Who Hijack Lorries And Buses Arrested In Enugu (PHOTO) @DONJAZZY @PoliceNG #HumanRights  https://t.co/XyFl8wy62g","target":1},"4550":{"id":6467,"keyword":"injured","location":"","text":"Washington Post - 4 dead dozens injured in Gaza blast near house leveled in summer war http://t.co/VjXa13n8Ap","target":1},"5157":{"id":7356,"keyword":"obliterate","location":"","text":"Whereas Jez will obliterate the national debt - and give lots of new benefits - by simply printing money! Genius! https://t.co/ReffbkVG9R","target":1},"5763":{"id":8225,"keyword":"riot","location":"","text":"@eac4AU You can now PRE-ORDER the film on ITUNES &amp; watch 9/15!! YAY! http://t.co/fVP3Wnid4L http://t.co/bwdhIBtiKs http://t.co/qelROcI7by","target":0},"6671":{"id":9562,"keyword":"thunder","location":"","text":"Am I hearing thunder or trucks?","target":0},"6984":{"id":10016,"keyword":"twister","location":"","text":"Crazy Mom Threw Teen Daughter a NUDE Twister Sex Party According To Her Friend59 more pics http://t.co/t94LNfwf34 http://t.co/roCyyEI2dM","target":0},"7541":{"id":10782,"keyword":"wreckage","location":" India","text":"Wreckage 'Conclusively Confirmed' as From MH370: Malaysia PM: Investigators and the families of those who were... http://t.co/1YIxFG1Hdy","target":1}},"rows_bottom":null},"text/plain":"         id       keyword                    location  \\\n1506   2174  catastrophic                               \n5763   8225          riot                               \n5157   7356    obliterate                               \n4550   6467       injured                               \n4329   6148        hijack                               \n1420   2049    casualties   Afghanistan United States   \n6984  10016       twister                               \n7541  10782      wreckage                       India   \n979    1418  body % 20bag                               \n6671   9562       thunder                               \n\n                                                   text  target  \n1506  The Catastrophic Effects of Hiroshima and Naga...       1  \n5763  @eac4AU You can now PRE-ORDER the film on ITUN...       0  \n5157  Whereas Jez will obliterate the national debt ...       1  \n4550  Washington Post - 4 dead dozens injured in Gaz...       1  \n4329  Criminals Who Hijack Lorries And Buses Arreste...       1  \n1420  #Afghanistan: sharp rise in women and children...       1  \n6984  Crazy Mom Threw Teen Daughter a NUDE Twister S...       0  \n7541  Wreckage 'Conclusively Confirmed' as From MH37...       1  \n979   genuine Leather man Bag Messenger fit iPad min...       0  \n6671                    Am I hearing thunder or trucks?       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1506</th>\n      <td>2174</td>\n      <td>catastrophic</td>\n      <td></td>\n      <td>The Catastrophic Effects of Hiroshima and Naga...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5763</th>\n      <td>8225</td>\n      <td>riot</td>\n      <td></td>\n      <td>@eac4AU You can now PRE-ORDER the film on ITUN...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5157</th>\n      <td>7356</td>\n      <td>obliterate</td>\n      <td></td>\n      <td>Whereas Jez will obliterate the national debt ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4550</th>\n      <td>6467</td>\n      <td>injured</td>\n      <td></td>\n      <td>Washington Post - 4 dead dozens injured in Gaz...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4329</th>\n      <td>6148</td>\n      <td>hijack</td>\n      <td></td>\n      <td>Criminals Who Hijack Lorries And Buses Arreste...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1420</th>\n      <td>2049</td>\n      <td>casualties</td>\n      <td>Afghanistan United States</td>\n      <td>#Afghanistan: sharp rise in women and children...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6984</th>\n      <td>10016</td>\n      <td>twister</td>\n      <td></td>\n      <td>Crazy Mom Threw Teen Daughter a NUDE Twister S...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7541</th>\n      <td>10782</td>\n      <td>wreckage</td>\n      <td>India</td>\n      <td>Wreckage 'Conclusively Confirmed' as From MH37...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>979</th>\n      <td>1418</td>\n      <td>body % 20bag</td>\n      <td></td>\n      <td>genuine Leather man Bag Messenger fit iPad min...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6671</th>\n      <td>9562</td>\n      <td>thunder</td>\n      <td></td>\n      <td>Am I hearing thunder or trucks?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"e9909010-7fe0-4c89-8310-9f4cd22de1a6","output_cleared":false},"source":"#Function to Vectorize and clean text\r\ndef hiICleanTrash(x):\r\n    # first pass to clean the punctuation\r\n    pass1  = \"\".join([char for char in x if char not in string.punctuation])\r\n    # second pass to clean the numbers up\r\n    pass2 = re.sub('[0-9]+', '', pass1)\r\n    # third pass to tokenize\r\n    pass3 = word_tokenize(pass2)\r\n    # fourth pass to use snowball to stem words if they're not a stopword\r\n    pass4 = [word for word in pass3 if word not in stop_w]\r\n    return (pass4)\r\nprint(hiICleanTrash(\"Hello! I like cleaning the trash. I found 4 occurances today!\"))","execution_count":null,"outputs":[{"name":"stdout","text":"['Hello', 'I', 'like', 'cleaning', 'trash', 'I', 'found', 'occurances', 'today']\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"1ce9d27d-bdd6-4a55-aee5-063b01fd3cce"},"source":"# print(set(stop_w))","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"0edb33b5-6ad7-45d5-b77b-57db87bbf59b","output_cleared":false},"source":"modified.text = modified.text.progress_apply(hiICleanTrash)\r\nmodded_test.text = modded_test.text.progress_apply(hiICleanTrash)","execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 7613/7613 [00:01<00:00, 4986.26it/s]\n100%|██████████| 3263/3263 [00:00<00:00, 4989.87it/s]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"19901935-0223-4f58-89e8-9d231017ae17","output_cleared":false},"source":"modified.sample(n=n,random_state=random_state)","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"application/vnd.deepnote.dataframe.v2+json":{"error":"Traceback (most recent call last):\n  File \"/home/jovyan/.deepnote/variable_explorer.py\", line 324, in dataframe_formatter\n    return { MIME_TYPE: describe_pd_dataframe(df) }\n  File \"/home/jovyan/.deepnote/variable_explorer_helpers.py\", line 91, in describe_pd_dataframe\n    'unique_count': column.dropna().nunique(),\n  File \"/opt/venv/lib/python3.7/site-packages/pandas/core/base.py\", line 1443, in nunique\n    uniqs = self.unique()\n  File \"/opt/venv/lib/python3.7/site-packages/pandas/core/series.py\", line 1984, in unique\n    result = super().unique()\n  File \"/opt/venv/lib/python3.7/site-packages/pandas/core/base.py\", line 1405, in unique\n    result = unique1d(values)\n  File \"/opt/venv/lib/python3.7/site-packages/pandas/core/algorithms.py\", line 405, in unique\n    uniques = table.unique(values)\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1767, in pandas._libs.hashtable.PyObjectHashTable.unique\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1718, in pandas._libs.hashtable.PyObjectHashTable._unique\nTypeError: unhashable type: 'list'\n"},"text/plain":"         id       keyword                    location  \\\n1506   2174  catastrophic                               \n5763   8225          riot                               \n5157   7356    obliterate                               \n4550   6467       injured                               \n4329   6148        hijack                               \n1420   2049    casualties   Afghanistan United States   \n6984  10016       twister                               \n7541  10782      wreckage                       India   \n979    1418  body % 20bag                               \n6671   9562       thunder                               \n\n                                                   text  target  \n1506  [The, Catastrophic, Effects, Hiroshima, Nagasa...       1  \n5763  [eacAU, You, PREORDER, film, ITUNES, amp, watc...       0  \n5157  [Whereas, Jez, obliterate, national, debt, giv...       1  \n4550  [Washington, Post, dead, dozens, injured, Gaza...       1  \n4329  [Criminals, Who, Hijack, Lorries, And, Buses, ...       1  \n1420  [Afghanistan, sharp, rise, women, children, ca...       1  \n6984  [Crazy, Mom, Threw, Teen, Daughter, NUDE, Twis...       0  \n7541  [Wreckage, Conclusively, Confirmed, From, MH, ...       1  \n979   [genuine, Leather, man, Bag, Messenger, fit, i...       0  \n6671                  [Am, I, hearing, thunder, trucks]       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1506</th>\n      <td>2174</td>\n      <td>catastrophic</td>\n      <td></td>\n      <td>[The, Catastrophic, Effects, Hiroshima, Nagasa...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5763</th>\n      <td>8225</td>\n      <td>riot</td>\n      <td></td>\n      <td>[eacAU, You, PREORDER, film, ITUNES, amp, watc...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5157</th>\n      <td>7356</td>\n      <td>obliterate</td>\n      <td></td>\n      <td>[Whereas, Jez, obliterate, national, debt, giv...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4550</th>\n      <td>6467</td>\n      <td>injured</td>\n      <td></td>\n      <td>[Washington, Post, dead, dozens, injured, Gaza...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4329</th>\n      <td>6148</td>\n      <td>hijack</td>\n      <td></td>\n      <td>[Criminals, Who, Hijack, Lorries, And, Buses, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1420</th>\n      <td>2049</td>\n      <td>casualties</td>\n      <td>Afghanistan United States</td>\n      <td>[Afghanistan, sharp, rise, women, children, ca...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6984</th>\n      <td>10016</td>\n      <td>twister</td>\n      <td></td>\n      <td>[Crazy, Mom, Threw, Teen, Daughter, NUDE, Twis...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7541</th>\n      <td>10782</td>\n      <td>wreckage</td>\n      <td>India</td>\n      <td>[Wreckage, Conclusively, Confirmed, From, MH, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>979</th>\n      <td>1418</td>\n      <td>body % 20bag</td>\n      <td></td>\n      <td>[genuine, Leather, man, Bag, Messenger, fit, i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6671</th>\n      <td>9562</td>\n      <td>thunder</td>\n      <td></td>\n      <td>[Am, I, hearing, thunder, trucks]</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"850a3a74-5faf-4777-8301-b2df2d70b583"},"source":"modded_test.sample(n=n,random_state=random_state)","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"application/vnd.deepnote.dataframe.v2+json":{"error":"Traceback (most recent call last):\n  File \"/home/jovyan/.deepnote/variable_explorer.py\", line 324, in dataframe_formatter\n    return { MIME_TYPE: describe_pd_dataframe(df) }\n  File \"/home/jovyan/.deepnote/variable_explorer_helpers.py\", line 91, in describe_pd_dataframe\n    'unique_count': column.dropna().nunique(),\n  File \"/opt/venv/lib/python3.7/site-packages/pandas/core/base.py\", line 1443, in nunique\n    uniqs = self.unique()\n  File \"/opt/venv/lib/python3.7/site-packages/pandas/core/series.py\", line 1984, in unique\n    result = super().unique()\n  File \"/opt/venv/lib/python3.7/site-packages/pandas/core/base.py\", line 1405, in unique\n    result = unique1d(values)\n  File \"/opt/venv/lib/python3.7/site-packages/pandas/core/algorithms.py\", line 405, in unique\n    uniques = table.unique(values)\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1767, in pandas._libs.hashtable.PyObjectHashTable.unique\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1718, in pandas._libs.hashtable.PyObjectHashTable._unique\nTypeError: unhashable type: 'list'\n"},"text/plain":"         id       keyword          location  \\\n805    2646       crashed               USA   \n2259   7511   oil%20spill           Houston   \n3091  10233       volcano       Hawaii, USA   \n1584   5360          fire        Wonderland   \n2941   9742       tragedy               NaN   \n1177   3882    detonation        ShloMotion   \n2235   7450  obliteration           Canada    \n1893   6378      hostages   Rocky Mountains   \n3228  10728         wreck  Philippians 4:13   \n1141   3767   destruction              Hell   \n\n                                                   text  \n805   [Website, Malfunctioning, PHP, Scripts, workin...  \n2259  [California, Spring, Oil, Spill, Estimate, Gro...  \n3091  [USGS, M, km, S, Volcano, Hawaii, Time, UTC, e...  \n1584                    [When, likes, Fire, IG, selfie]  \n2941  [Rly, tragedy, MP, Some, live, recount, horror...  \n1177  [JerusalemPost, WATCH, Israel, performs, contr...  \n2235  [Need, conquest, server, CTE, theyre, Russian,...  \n1893  [Sinjar, Massacre, Yazidis, Blast, Lack, Actio...  \n3228                             [Dj, wreck, cut, beat]  \n1141  [iamdestruction, Okay, Ill, put, tail, first, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>805</th>\n      <td>2646</td>\n      <td>crashed</td>\n      <td>USA</td>\n      <td>[Website, Malfunctioning, PHP, Scripts, workin...</td>\n    </tr>\n    <tr>\n      <th>2259</th>\n      <td>7511</td>\n      <td>oil%20spill</td>\n      <td>Houston</td>\n      <td>[California, Spring, Oil, Spill, Estimate, Gro...</td>\n    </tr>\n    <tr>\n      <th>3091</th>\n      <td>10233</td>\n      <td>volcano</td>\n      <td>Hawaii, USA</td>\n      <td>[USGS, M, km, S, Volcano, Hawaii, Time, UTC, e...</td>\n    </tr>\n    <tr>\n      <th>1584</th>\n      <td>5360</td>\n      <td>fire</td>\n      <td>Wonderland</td>\n      <td>[When, likes, Fire, IG, selfie]</td>\n    </tr>\n    <tr>\n      <th>2941</th>\n      <td>9742</td>\n      <td>tragedy</td>\n      <td>NaN</td>\n      <td>[Rly, tragedy, MP, Some, live, recount, horror...</td>\n    </tr>\n    <tr>\n      <th>1177</th>\n      <td>3882</td>\n      <td>detonation</td>\n      <td>ShloMotion</td>\n      <td>[JerusalemPost, WATCH, Israel, performs, contr...</td>\n    </tr>\n    <tr>\n      <th>2235</th>\n      <td>7450</td>\n      <td>obliteration</td>\n      <td>Canada</td>\n      <td>[Need, conquest, server, CTE, theyre, Russian,...</td>\n    </tr>\n    <tr>\n      <th>1893</th>\n      <td>6378</td>\n      <td>hostages</td>\n      <td>Rocky Mountains</td>\n      <td>[Sinjar, Massacre, Yazidis, Blast, Lack, Actio...</td>\n    </tr>\n    <tr>\n      <th>3228</th>\n      <td>10728</td>\n      <td>wreck</td>\n      <td>Philippians 4:13</td>\n      <td>[Dj, wreck, cut, beat]</td>\n    </tr>\n    <tr>\n      <th>1141</th>\n      <td>3767</td>\n      <td>destruction</td>\n      <td>Hell</td>\n      <td>[iamdestruction, Okay, Ill, put, tail, first, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"28d732b7-f112-4999-a38b-8cd2989839ed"},"source":"setofwords = set(modified[\"text\"].sum())\r\nprint(len(setofwords))","execution_count":null,"outputs":[{"name":"stdout","text":"25832\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"e65f3d55-d51c-474e-b1fa-223b0fad21b5","output_cleared":true},"source":"# Create a new df\r\nmodel_df = pd.DataFrame()","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"0b8af6c4-6b6c-4cac-aadf-1ad95bf12c13","output_cleared":true},"source":"def get_info():\r\n    fig = px.box(model_df.melt(var_name=\"Model\"),\r\n        y=\"value\",labels={\r\n            'value':'Accuracy'\r\n        },\r\n        facet_col=\"Model\", color=\"Model\",\r\n        boxmode=\"overlay\",\r\n        points='all')\r\n    # Remove the Model = **\r\n    fig.for_each_annotation(lambda a: a.update(text=''))\r\n    fig.show()\r\n    ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Getting started for using tensorflow and keras","metadata":{"tags":[],"cell_id":"bd7cd6d1-be8d-4e88-832b-a15e2a7edcac"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"37ef3c42-2b4e-494b-a5ae-ef5c20e541ff","output_cleared":false},"source":"# Tensorflow and Keras imports\r\nimport tensorflow as tf\r\n# Importing the layers we may use\r\nfrom tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\r\nfrom tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\r\nfrom tensorflow.keras.models import Model, Sequential\r\nfrom tensorflow.keras import layers\r\n# keras preprocessing tokenizer\r\nfrom tensorflow.keras.preprocessing.text import Tokenizer\r\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"01684376-17ef-46c3-8cdf-fcdbe80a2998","output_cleared":false},"source":"# Hyperparameters\r\nvocab_size = 10000\r\nembedding_dim = 32\r\n# idk for max length, tweets are like 280chars long\r\nmax_length = 80\r\ntrunc_type = 'post'\r\npadding_type = 'post'\r\noov_tok = '<OOV>'\r\ndropout_ratio = 0.5\r\ntraining_portion = .8\r\n# tf stuff\r\nprint(tf.__version__)\r\nprint(tf.executing_eagerly())\r\ntest_corpus=modded_test['text']\r\n#input_dim: This is the size of the vocabulary in the text data. For example, if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\r\n#output_dim: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\r\n#input_length: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are comprised of 1000 words, this would be 1000.","execution_count":null,"outputs":[{"name":"stdout","text":"2.2.0\nTrue\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Run till before the hiIcleanTrash cell!!!","metadata":{"tags":[],"cell_id":"be5dd653-44ee-4e77-9553-2d27d392d1d4"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"eae4c7c9-45a9-4c08-b168-a6f4adfb8311","output_cleared":false},"source":"def make_splits(modified, verbose=0):\r\n    train_size = int(len(modified) * training_portion)\r\n    # train split \r\n    train_corpus = modified['text'][0: train_size]\r\n    train_labels = modified['target'][0: train_size]\r\n    # validation split\r\n    validation_corpus = modified['text'][train_size:]\r\n    validation_labels = modified['target'][train_size:]\r\n    if(verbose):\r\n        print(train_size)\r\n        print((train_mat))\r\n        print((train_labels))\r\n        print((validation_mat))\r\n        print((validation_labels))\r\n    return train_corpus, train_labels, validation_corpus, validation_labels","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"097e12ea-0b42-4812-ab7f-e51bf3acf72c","output_cleared":false},"source":"train_corpus, train_labels, validation_corpus, validation_labels = make_splits(modified)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"e01bc3d7-8a5c-4b2c-81a3-04bf66e774ce"},"source":"test","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"application/vnd.deepnote.dataframe.v2+json":{"error":"Traceback (most recent call last):\n  File \"/home/jovyan/.deepnote/variable_explorer.py\", line 324, in dataframe_formatter\n    return { MIME_TYPE: describe_pd_dataframe(df) }\n  File \"/home/jovyan/.deepnote/variable_explorer_helpers.py\", line 91, in describe_pd_dataframe\n    'unique_count': column.dropna().nunique(),\n  File \"/opt/venv/lib/python3.7/site-packages/pandas/core/base.py\", line 1443, in nunique\n    uniqs = self.unique()\n  File \"/opt/venv/lib/python3.7/site-packages/pandas/core/series.py\", line 1984, in unique\n    result = super().unique()\n  File \"/opt/venv/lib/python3.7/site-packages/pandas/core/base.py\", line 1405, in unique\n    result = unique1d(values)\n  File \"/opt/venv/lib/python3.7/site-packages/pandas/core/algorithms.py\", line 405, in unique\n    uniques = table.unique(values)\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1767, in pandas._libs.hashtable.PyObjectHashTable.unique\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1718, in pandas._libs.hashtable.PyObjectHashTable._unique\nTypeError: unhashable type: 'list'\n"},"text/plain":"         id keyword location  \\\n0         0     NaN      NaN   \n1         2     NaN      NaN   \n2         3     NaN      NaN   \n3         9     NaN      NaN   \n4        11     NaN      NaN   \n...     ...     ...      ...   \n3258  10861     NaN      NaN   \n3259  10865     NaN      NaN   \n3260  10868     NaN      NaN   \n3261  10874     NaN      NaN   \n3262  10875     NaN      NaN   \n\n                                                   text  \n0                [Just, happened, terrible, car, crash]  \n1     [Heard, earthquake, different, cities, stay, s...  \n2     [forest, fire, spot, pond, geese, fleeing, acr...  \n3            [Apocalypse, lighting, Spokane, wildfires]  \n4             [Typhoon, Soudelor, kills, China, Taiwan]  \n...                                                 ...  \n3258  [EARTHQUAKE, SAFETY, LOS, ANGELES, ÛÒ, SAFETY...  \n3259  [Storm, RI, worse, last, hurricane, My, cityam...  \n3260  [Green, Line, derailment, Chicago, httptcoUtbX...  \n3261  [MEG, issues, Hazardous, Weather, Outlook, HWO...  \n3262  [CityofCalgary, activated, Municipal, Emergenc...  \n\n[3263 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[Just, happened, terrible, car, crash]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[Heard, earthquake, different, cities, stay, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[forest, fire, spot, pond, geese, fleeing, acr...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[Apocalypse, lighting, Spokane, wildfires]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[Typhoon, Soudelor, kills, China, Taiwan]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>12</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[Were, shakingIts, earthquake]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>21</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[Theyd, probably, still, show, life, Arsenal, ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>22</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[Hey, How]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>27</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[What, nice, hat]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>29</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[Fuck]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>30</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[No, I, dont, like, cold]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>35</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[NOOOOOOOOO, Dont]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>42</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[No, dont, tell]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>43</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[What]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>45</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[Awesome]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>46</td>\n      <td>ablaze</td>\n      <td>London</td>\n      <td>[Birmingham, Wholesale, Market, ablaze, BBC, N...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>47</td>\n      <td>ablaze</td>\n      <td>Niall's place | SAF 12 SQUAD |</td>\n      <td>[sunkxssedharry, wear, shorts, race, ablaze]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>51</td>\n      <td>ablaze</td>\n      <td>NIGERIA</td>\n      <td>[PreviouslyOnDoyinTv, Toke, MakinwaÛªs, marri...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>58</td>\n      <td>ablaze</td>\n      <td>Live On Webcam</td>\n      <td>[Check, httptcorOINSmEJJ, httptcoTjZjiN, httpt...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>60</td>\n      <td>ablaze</td>\n      <td>Los Angeles, Califnordia</td>\n      <td>[PSA, IÛªm, splitting, personalities, techies...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>69</td>\n      <td>ablaze</td>\n      <td>threeonefive.</td>\n      <td>[beware, world, ablaze, sierra, leone, amp, guap]</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>70</td>\n      <td>ablaze</td>\n      <td>Washington State</td>\n      <td>[Burning, Man, Ablaze, Turban, Diva, httptcoho...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>72</td>\n      <td>ablaze</td>\n      <td>Whoop Ass, Georgia</td>\n      <td>[Not, diss, song, People, take, thing, run, Sm...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>75</td>\n      <td>ablaze</td>\n      <td>India</td>\n      <td>[Rape, victim, dies, sets, ablaze, A, yearold,...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>84</td>\n      <td>ablaze</td>\n      <td>NaN</td>\n      <td>[SETTING, MYSELF, ABLAZE, httptcovMePXhC]</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>87</td>\n      <td>ablaze</td>\n      <td>scarborough, ontario</td>\n      <td>[CTVToronto, bins, front, field, house, wer, s...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>88</td>\n      <td>ablaze</td>\n      <td>NaN</td>\n      <td>[nowplaying, Alfons, Ablaze, Puls, Radio, puls...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>90</td>\n      <td>ablaze</td>\n      <td>121 N La Salle St, Suite 500</td>\n      <td>[Burning, Rahm, Lets, hope, City, Hall, builds...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>94</td>\n      <td>ablaze</td>\n      <td>Wandering</td>\n      <td>[PhilippaEilhart, DhuBlath, hurt, eyes, ablaze...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>99</td>\n      <td>accident</td>\n      <td>Homewood, PA</td>\n      <td>[Accident, cleared, PaTurnpike, PATP, EB, PA, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3233</th>\n      <td>10756</td>\n      <td>wreckage</td>\n      <td>Mumbai</td>\n      <td>[Wreckage, Conclusively, Confirmed, From, MH, ...</td>\n    </tr>\n    <tr>\n      <th>3234</th>\n      <td>10757</td>\n      <td>wreckage</td>\n      <td>NaN</td>\n      <td>[science, Now, piece, wreckage, flight, MH, co...</td>\n    </tr>\n    <tr>\n      <th>3235</th>\n      <td>10758</td>\n      <td>wreckage</td>\n      <td>India</td>\n      <td>[Wreckage, Conclusively, Confirmed, From, MH, ...</td>\n    </tr>\n    <tr>\n      <th>3236</th>\n      <td>10761</td>\n      <td>wreckage</td>\n      <td>Mumbai</td>\n      <td>[Wreckage, Conclusively, Confirmed, From, MH, ...</td>\n    </tr>\n    <tr>\n      <th>3237</th>\n      <td>10762</td>\n      <td>wreckage</td>\n      <td>Canada</td>\n      <td>[TOP, STORY, wreckage, MH, officially, confirm...</td>\n    </tr>\n    <tr>\n      <th>3238</th>\n      <td>10773</td>\n      <td>wreckage</td>\n      <td>NaN</td>\n      <td>[Wreckage, Conclusively, Confirmed, From, MH, ...</td>\n    </tr>\n    <tr>\n      <th>3239</th>\n      <td>10778</td>\n      <td>wreckage</td>\n      <td>Mumbai</td>\n      <td>[Wreckage, Conclusively, Confirmed, From, MH, ...</td>\n    </tr>\n    <tr>\n      <th>3240</th>\n      <td>10781</td>\n      <td>wreckage</td>\n      <td>our galaxy</td>\n      <td>[RT, australian, Debris, found, Indian, Ocean,...</td>\n    </tr>\n    <tr>\n      <th>3241</th>\n      <td>10791</td>\n      <td>wrecked</td>\n      <td>Sunny Southern California</td>\n      <td>[Cramer, Igers, words, wrecked, Disneys, stock...</td>\n    </tr>\n    <tr>\n      <th>3242</th>\n      <td>10792</td>\n      <td>wrecked</td>\n      <td>Plymouth, England</td>\n      <td>[Almost, wrecked, van, day, guy, yeah, I, brak...</td>\n    </tr>\n    <tr>\n      <th>3243</th>\n      <td>10796</td>\n      <td>wrecked</td>\n      <td>Deep in the heart of LibLand</td>\n      <td>[What, manner, human, would, parcel, baby, tho...</td>\n    </tr>\n    <tr>\n      <th>3244</th>\n      <td>10797</td>\n      <td>wrecked</td>\n      <td>NaN</td>\n      <td>[NathanRFC, thought, said, Saturday, night, ne...</td>\n    </tr>\n    <tr>\n      <th>3245</th>\n      <td>10801</td>\n      <td>wrecked</td>\n      <td>Canada,Ontario</td>\n      <td>[I, wan, na, ease, mind, make, feel, alright]</td>\n    </tr>\n    <tr>\n      <th>3246</th>\n      <td>10804</td>\n      <td>wrecked</td>\n      <td>Love Reiss</td>\n      <td>[yakubOObs, think, deactivated, notifications,...</td>\n    </tr>\n    <tr>\n      <th>3247</th>\n      <td>10806</td>\n      <td>wrecked</td>\n      <td>Seattle Washington</td>\n      <td>[RT, CNBC, words, Disney, CEO, Bob, Iger, wrec...</td>\n    </tr>\n    <tr>\n      <th>3248</th>\n      <td>10807</td>\n      <td>wrecked</td>\n      <td>Acey mountain islanddåÇTorontoåÈ</td>\n      <td>[Smackdown, tyme, put, good, mood, since, got,...</td>\n    </tr>\n    <tr>\n      <th>3249</th>\n      <td>10816</td>\n      <td>wrecked</td>\n      <td>los angeles</td>\n      <td>[thrillhho, jsyk, I, havent, stopped, thinking...</td>\n    </tr>\n    <tr>\n      <th>3250</th>\n      <td>10820</td>\n      <td>wrecked</td>\n      <td>Brussels, Belgium</td>\n      <td>[stighefootball, Begovic, garbage, He, got, wr...</td>\n    </tr>\n    <tr>\n      <th>3251</th>\n      <td>10828</td>\n      <td>wrecked</td>\n      <td>NaN</td>\n      <td>[Wrecked, today, got, hattrick]</td>\n    </tr>\n    <tr>\n      <th>3252</th>\n      <td>10836</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[Ebola, EbolaOutbreak, Ebola, Virus, Birmingha...</td>\n    </tr>\n    <tr>\n      <th>3253</th>\n      <td>10838</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[Malaysian, PM, confirms, debris, missing, fli...</td>\n    </tr>\n    <tr>\n      <th>3254</th>\n      <td>10845</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[Officials, Alabama, home, quarantined, possib...</td>\n    </tr>\n    <tr>\n      <th>3255</th>\n      <td>10856</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[See, yr, old, PKK, suicide, bomber, detonated...</td>\n    </tr>\n    <tr>\n      <th>3256</th>\n      <td>10857</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[To, conference, attendees, The, blue, line, a...</td>\n    </tr>\n    <tr>\n      <th>3257</th>\n      <td>10858</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[The, death, toll, ISsuicide, car, bombing, YP...</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>10861</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[EARTHQUAKE, SAFETY, LOS, ANGELES, ÛÒ, SAFETY...</td>\n    </tr>\n    <tr>\n      <th>3259</th>\n      <td>10865</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[Storm, RI, worse, last, hurricane, My, cityam...</td>\n    </tr>\n    <tr>\n      <th>3260</th>\n      <td>10868</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[Green, Line, derailment, Chicago, httptcoUtbX...</td>\n    </tr>\n    <tr>\n      <th>3261</th>\n      <td>10874</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[MEG, issues, Hazardous, Weather, Outlook, HWO...</td>\n    </tr>\n    <tr>\n      <th>3262</th>\n      <td>10875</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[CityofCalgary, activated, Municipal, Emergenc...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"73cee60c-bfb0-4788-b837-c600de9a3076","output_cleared":false},"source":"def make_tokenized_sequences(train_corpus, validation_corpus,test_corpus, verbose=0):\r\n    tokenizer = Tokenizer(num_words=vocab_size,\r\n                          oov_token=oov_tok,\r\n                          filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',\r\n                          lower=True)\r\n    tokenizer.fit_on_texts(train_corpus)\r\n\r\n    word_index = tokenizer.word_index\r\n    if(verbose):\r\n        dict(list(word_index.items())[0:10])\r\n    \r\n    train_sequences = tokenizer.texts_to_sequences(train_corpus)\r\n    train_padded = pad_sequences(train_sequences, maxlen=max_length,\r\n                                    padding=padding_type, truncating=trunc_type)\r\n\r\n    validation_sequences = tokenizer.texts_to_sequences(validation_corpus)\r\n    validation_padded = pad_sequences(validation_sequences, maxlen=max_length,\r\n                                        padding=padding_type, truncating=trunc_type)\r\n\r\n    test_sequences = tokenizer.texts_to_sequences(test_corpus)\r\n    test_padded = pad_sequences(test_sequences, maxlen=max_length,\r\n                                        padding=padding_type, truncating=trunc_type)\r\n    \r\n    if(verbose):\r\n        print(train_sequences[10])\r\n        print(train_mat[10])\r\n    \r\n    return train_padded, validation_padded, test_padded","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"2a15f5a2-59dc-4674-94fc-0d35cef8bf07","output_cleared":false},"source":"train_padded, validation_padded, test_padded = make_tokenized_sequences(train_corpus, validation_corpus, test_corpus)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"e4f16215-093b-4222-84ad-e78c43cae482","output_cleared":false},"source":"def compile_and_run(num_epochs, model_name='best_model', verbose=1, dropout_ratio=dropout_ratio):\r\n    model = Sequential([\r\n    # add an Embedding layer expecting input vocab of size vocab_size,\r\n    # and output embedding dimension of size embedding_dim\r\n    Embedding(vocab_size, embedding_dim),\r\n    Bidirectional(LSTM(embedding_dim)),\r\n    Dropout(dropout_ratio),\r\n    Dense(embedding_dim,activation='relu'),\r\n    Dense(2, activation='softmax')\r\n    ])\r\n    if(verbose):\r\n        model.summary()\r\n        print(\"Dropout ratio is {}\".format(dropout_ratio))\r\n    \r\n    # Early Stopping callback setup\r\n    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.05,\r\n                                        mode='min', patience=10, verbose=1)\r\n\r\n    # Model Checkpoint callback setup\r\n    mc = tf.keras.callbacks.ModelCheckpoint(model_name+'.h5', monitor='val_accuracy',\r\n                                            mode='max', verbose=1, save_best_only=True)\r\n\r\n    model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\r\n\r\n    history = model.fit(train_padded, train_labels,epochs=num_epochs, validation_data=(validation_padded, validation_labels), verbose=verbose, callbacks=[es, mc], shuffle=True)\r\n\r\n    return history\r\n\r\nmodel_history = compile_and_run(20, dropout_ratio=0.5)","execution_count":null,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, None, 100)         1000000   \n_________________________________________________________________\nbidirectional (Bidirectional (None, 200)               160800    \n_________________________________________________________________\ndropout (Dropout)            (None, 200)               0         \n_________________________________________________________________\ndense (Dense)                (None, 100)               20100     \n_________________________________________________________________\ndense_1 (Dense)              (None, 2)                 202       \n=================================================================\nTotal params: 1,181,102\nTrainable params: 1,181,102\nNon-trainable params: 0\n_________________________________________________________________\nDropout ratio is 0.5\nEpoch 1/20\n188/191 [============================>.] - ETA: 0s - loss: 0.5410 - accuracy: 0.7222\nEpoch 00001: val_accuracy improved from -inf to 0.77741, saving model to best_model.h5\n191/191 [==============================] - 4s 20ms/step - loss: 0.5410 - accuracy: 0.7222 - val_loss: 0.4714 - val_accuracy: 0.7774\nEpoch 2/20\n188/191 [============================>.] - ETA: 0s - loss: 0.3324 - accuracy: 0.8612\nEpoch 00002: val_accuracy did not improve from 0.77741\n191/191 [==============================] - 3s 16ms/step - loss: 0.3319 - accuracy: 0.8612 - val_loss: 0.5463 - val_accuracy: 0.7426\nEpoch 3/20\n189/191 [============================>.] - ETA: 0s - loss: 0.2269 - accuracy: 0.9129\nEpoch 00003: val_accuracy did not improve from 0.77741\n191/191 [==============================] - 3s 16ms/step - loss: 0.2272 - accuracy: 0.9131 - val_loss: 0.5406 - val_accuracy: 0.7748\nEpoch 4/20\n191/191 [==============================] - ETA: 0s - loss: 0.1601 - accuracy: 0.9430\nEpoch 00004: val_accuracy did not improve from 0.77741\n191/191 [==============================] - 3s 15ms/step - loss: 0.1601 - accuracy: 0.9430 - val_loss: 0.6916 - val_accuracy: 0.7702\nEpoch 5/20\n189/191 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 0.9611\nEpoch 00005: val_accuracy did not improve from 0.77741\n191/191 [==============================] - 3s 15ms/step - loss: 0.1164 - accuracy: 0.9611 - val_loss: 0.7271 - val_accuracy: 0.7610\nEpoch 6/20\n191/191 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9680\nEpoch 00006: val_accuracy did not improve from 0.77741\n191/191 [==============================] - 3s 16ms/step - loss: 0.0860 - accuracy: 0.9680 - val_loss: 0.8841 - val_accuracy: 0.7413\nEpoch 7/20\n188/191 [============================>.] - ETA: 0s - loss: 0.0710 - accuracy: 0.9722\nEpoch 00007: val_accuracy did not improve from 0.77741\n191/191 [==============================] - 3s 16ms/step - loss: 0.0720 - accuracy: 0.9718 - val_loss: 1.1789 - val_accuracy: 0.7137\nEpoch 8/20\n189/191 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 0.9757\nEpoch 00008: val_accuracy did not improve from 0.77741\n191/191 [==============================] - 3s 15ms/step - loss: 0.0591 - accuracy: 0.9754 - val_loss: 1.1210 - val_accuracy: 0.7328\nEpoch 9/20\n188/191 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9774\nEpoch 00009: val_accuracy did not improve from 0.77741\n191/191 [==============================] - 3s 15ms/step - loss: 0.0555 - accuracy: 0.9773 - val_loss: 1.6402 - val_accuracy: 0.7242\nEpoch 10/20\n191/191 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.9775\nEpoch 00010: val_accuracy did not improve from 0.77741\n191/191 [==============================] - 3s 15ms/step - loss: 0.0484 - accuracy: 0.9775 - val_loss: 1.6942 - val_accuracy: 0.7216\nEpoch 11/20\n189/191 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.9793\nEpoch 00011: val_accuracy did not improve from 0.77741\n191/191 [==============================] - 3s 15ms/step - loss: 0.0438 - accuracy: 0.9793 - val_loss: 1.7708 - val_accuracy: 0.7085\nEpoch 00011: early stopping\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"ba04b55d-c436-448a-90ec-7df8bbe0c871","output_cleared":false},"source":"def eval_best_model(model_name='best_model'):\r\n    saved_model = tf.keras.models.load_model(model_name+'.h5')\r\n    saved_model.summary()\r\n    # evaluate the model\r\n    _, train_acc = saved_model.evaluate(train_padded, train_labels, verbose=0)\r\n    _, test_acc = saved_model.evaluate(validation_padded, validation_labels, verbose=0)\r\n\r\n    print('Train: %.5f, Test: %.5f' % (train_acc, test_acc))\r\n\r\neval_best_model()","execution_count":null,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, None, 100)         1000000   \n_________________________________________________________________\nbidirectional (Bidirectional (None, 200)               160800    \n_________________________________________________________________\ndropout (Dropout)            (None, 200)               0         \n_________________________________________________________________\ndense (Dense)                (None, 100)               20100     \n_________________________________________________________________\ndense_1 (Dense)              (None, 2)                 202       \n=================================================================\nTotal params: 1,181,102\nTrainable params: 1,181,102\nNon-trainable params: 0\n_________________________________________________________________\nTrain: 0.87718, Test: 0.77741\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Doing the submission steps:","metadata":{"tags":[],"cell_id":"2722e7c8-3895-4b4b-a7ef-df2cbcaac143"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"da5e2b4f-6348-4183-a6a1-57507649b1bd"},"source":"saved_model = tf.keras.models.load_model('best_model.h5')\r\n\r\npredicted  = saved_model.predict(test_padded)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"0e23c837-2eff-4b48-adb1-6727e43d7cd0"},"source":"sub=pd.DataFrame({'id':test['id'].values.tolist(),'target':tf.argmax(input=predicted, axis=1)})\r\nsub.sample(n=n,random_state=random_state)","execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'pd' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-268a70091666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"50550e7c-f02b-4426-a98a-298364390f3b"},"source":"sub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"cell_type":"code","source":"## NEW MODELS","metadata":{"tags":[],"cell_id":"4b0ea90a-db20-451a-ac48-4e1499e652b7"},"outputs":[],"execution_count":1},{"cell_type":"code","metadata":{"tags":[],"cell_id":"b5bad44e-fa5e-46c7-9f5a-1a3ca135c4d9"},"source":"#new models \r\n\r\n#GloVe is an unsupervised learning algorithm\r\n# for obtaining vector representations for words\r\nzip_file = \"http://nlp.stanford.edu/data/glove.6B.zip\"\r\nimport requests, zipfile, io\r\nr = requests.get(zip_file)\r\nz = zipfile.ZipFile(io.BytesIO(r.content))\r\nz.extractall()","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"4fbab130-5466-4545-912c-619c8a811501"},"source":"embeddings_index = dict()\r\nf = open('glove.6B.100d.txt')\r\nfor line in f:\r\n    values = line.split()\r\n    word = values[0]\r\n    coefs = np.asarray(values[1:], dtype='float32')\r\n    embeddings_index[word] = coefs\r\nf.close()","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"5a28fdbe-5bb6-4b7c-ac3d-0a55fe1b4fea"},"source":"","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"dc499ab9-99ad-493e-be14-77e9bc0a8c89"},"source":"#print(\"no of words in glove dictionary is \"+str(len(embeddings_index)))\r\n#IGNORE\r\nembedding_matrix = np.zeros((VOCAB_SIZE, EMBED_DIM))\r\nindex  = 0\r\ndef embedpls(word,index):\r\n    for element in word:\r\n        embedding_vector = embeddings_index.get(element)\r\n        print(index)\r\n        if embedding_vector is not None:\r\n            embedding_matrix[index] = embedding_vector\r\n        index=index+1  \r\nmodified[\"text\"].apply(lambda x: embedpls(x,index))","execution_count":null,"outputs":[{"name":"stdout","text":"2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n4\n5\n6\n7\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n4\n5\n6\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n0\n1\n2\n3\n4\n5\n6\n7\n8\n0\n1\n2\n3\n4\n5\n6\n0\n1\n2\n3\n4\n5\n6\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n4\n5\n6\n7\n0\n1\n2\n3\n4\n5\n6\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n0\n1\n2\n3\n4\n5\n6\n0\n1\n2\n3\n4\n0\n1\n2\n3\n4\n0\n1\n2\n0\n1\n2\n3\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n4\n0\n1\n2\n3\n4\n5\n6\n7\n0\n1\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n0\n1\n2\n3\n4\n5\n6\n7\n8\n0\n1\n2\n3\n4\n5\n6\n7\n8\n0\n1\n2\n3\n4\n5\n6\n7\n8\n0\n1\n2\n3\n4\n0\n1\n2\n3\n4\n5\n6\n7\n8\n0\n1\n2\n3\n4\n5\n0\n1\n2\n3\n4\n5\n0\n1\n2\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n0\n1\n2\n3\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n4\n5\n6\n0\n1\n2\n3\n4\n5\n6\n7\n8\n0\n1\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n0\n1\n2\n3\n4\n5\n6\n7\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n6\n7\n8\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n0\n1\n2\n3\n4\n5\n6\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n0\n1\n2\n3\n4\n5\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n0\n1\n2\n3\n4\n5\n6\n7\n8\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n0\n1\n2\n3\n4\n5\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n","output_type":"stream"},{"output_type":"execute_result","execution_count":101,"data":{"text/plain":"0       None\n1       None\n2       None\n3       None\n4       None\n        ... \n7608    None\n7609    None\n7610    None\n7611    None\n7612    None\nName: text, Length: 7613, dtype: object"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"d7423928-051e-4302-b809-cc8913f49e4c"},"source":"print(embedding_matrix[31])","execution_count":null,"outputs":[{"name":"stdout","text":"[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0.]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"0e4e0547-3aa0-41c1-80e0-c0e494e80d7c"},"source":"texts = [text for text in modified[\"text\"]]\r\ntokenizer = Tokenizer(filters= \"'!#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\") \r\ntokenizer.fit_on_texts(texts)\r\nsequences = tokenizer.texts_to_sequences(texts)\r\nword_index = tokenizer.word_index","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"45a20add-5e13-44af-ba40-aa4832dcdbc1"},"source":"#print(word_index)  #word,index  it is a dictionary","execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'dict' object has no attribute 'iloc'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-138-e5a984c83f09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#print(word_index)  #word,index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'iloc'"]}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"a2523f01-bb17-4dd1-80a8-2c94057f4c16"},"source":"VOCAB_SIZE = len(word_index)\r\nEMBED_DIM = 100","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"9ee1ad9c-7899-4d88-8a78-da1180861556"},"source":"embedding_matrix = np.zeros((VOCAB_SIZE, EMBED_DIM)) #has the weights\r\nfor word,index in word_index.items():\r\n    if embeddings_index.get(word) is not None: #get() returns a value for the given key\r\n        embedding_matrix[index] = embeddings_index.get(word) #has the coeff of the weight ","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"d04195c7-eab6-4811-88bb-2d8ebb44e4c6"},"source":"embedding_matrix.shape\r\nprint(embedding_matrix)","execution_count":null,"outputs":[{"name":"stdout","text":"[[ 0.          0.          0.         ...  0.          0.\n   0.        ]\n [-0.046539    0.61966002  0.56647003 ... -0.37616    -0.032502\n   0.80620003]\n [-0.038194   -0.24487001  0.72812003 ... -0.1459      0.82779998\n   0.27061999]\n ...\n [ 0.          0.          0.         ...  0.          0.\n   0.        ]\n [ 0.          0.          0.         ...  0.          0.\n   0.        ]\n [ 0.          0.          0.         ...  0.          0.\n   0.        ]]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"168f2632-f765-450f-8ea2-3be0f95acbd9"},"source":"def glove(num_epochs, model_name='glove_model', verbose=1, dropout_ratio=dropout_ratio):\r\n    model = Sequential([\r\n    # add an Embedding layer expecting input vocab of size vocab_size,\r\n    # and output embedding dimension of size embedding_dim\r\n    Embedding(VOCAB_SIZE,EMBED_DIM,weights=[embedding_matrix],trainable=False),\r\n    Bidirectional(LSTM(EMBED_DIM)),\r\n    Dropout(dropout_ratio),\r\n    Dense(EMBED_DIM,activation='relu'),\r\n    Dense(2, activation='softmax')\r\n    ])\r\n    if(verbose):\r\n        model.summary()\r\n        print(\"Dropout ratio is {}\".format(dropout_ratio))\r\n    \r\n    # Early Stopping callback setup\r\n    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.05,\r\n                                        mode='min', patience=10, verbose=1)\r\n\r\n    # Model Checkpoint callback setup\r\n    mc = tf.keras.callbacks.ModelCheckpoint(model_name+'.h5', monitor='val_accuracy',\r\n                                            mode='max', verbose=1, save_best_only=True)\r\n\r\n    model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\r\n\r\n    history = model.fit(train_padded, train_labels,epochs=num_epochs, validation_data=(validation_padded, validation_labels), verbose=verbose, callbacks=[es, mc], shuffle=True)\r\n\r\n    return history\r\n\r\nmodel_history = glove(20, dropout_ratio=0.3)","execution_count":null,"outputs":[{"name":"stdout","text":"Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_3 (Embedding)      (None, None, 100)         2181000   \n_________________________________________________________________\nbidirectional_2 (Bidirection (None, 200)               160800    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 200)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 100)               20100     \n_________________________________________________________________\ndense_5 (Dense)              (None, 2)                 202       \n=================================================================\nTotal params: 2,362,102\nTrainable params: 181,102\nNon-trainable params: 2,181,000\n_________________________________________________________________\nDropout ratio is 0.3\nEpoch 1/20\n188/191 [============================>.] - ETA: 0s - loss: 0.6576 - accuracy: 0.6169\nEpoch 00001: val_accuracy improved from -inf to 0.56730, saving model to glove_model.h5\n191/191 [==============================] - 3s 16ms/step - loss: 0.6575 - accuracy: 0.6169 - val_loss: 0.6836 - val_accuracy: 0.5673\nEpoch 2/20\n190/191 [============================>.] - ETA: 0s - loss: 0.6020 - accuracy: 0.6806\nEpoch 00002: val_accuracy improved from 0.56730 to 0.61195, saving model to glove_model.h5\n191/191 [==============================] - 2s 13ms/step - loss: 0.6019 - accuracy: 0.6806 - val_loss: 0.6507 - val_accuracy: 0.6120\nEpoch 3/20\n191/191 [==============================] - ETA: 0s - loss: 0.5556 - accuracy: 0.7120\nEpoch 00003: val_accuracy improved from 0.61195 to 0.61458, saving model to glove_model.h5\n191/191 [==============================] - 2s 12ms/step - loss: 0.5556 - accuracy: 0.7120 - val_loss: 0.6681 - val_accuracy: 0.6146\nEpoch 4/20\n190/191 [============================>.] - ETA: 0s - loss: 0.5131 - accuracy: 0.7503\nEpoch 00004: val_accuracy improved from 0.61458 to 0.65135, saving model to glove_model.h5\n191/191 [==============================] - 2s 13ms/step - loss: 0.5132 - accuracy: 0.7504 - val_loss: 0.6750 - val_accuracy: 0.6513\nEpoch 5/20\n190/191 [============================>.] - ETA: 0s - loss: 0.4693 - accuracy: 0.7785\nEpoch 00005: val_accuracy improved from 0.65135 to 0.66448, saving model to glove_model.h5\n191/191 [==============================] - 2s 13ms/step - loss: 0.4700 - accuracy: 0.7785 - val_loss: 0.6243 - val_accuracy: 0.6645\nEpoch 6/20\n191/191 [==============================] - ETA: 0s - loss: 0.4194 - accuracy: 0.8135\nEpoch 00006: val_accuracy did not improve from 0.66448\n191/191 [==============================] - 2s 12ms/step - loss: 0.4194 - accuracy: 0.8135 - val_loss: 0.6306 - val_accuracy: 0.6645\nEpoch 7/20\n191/191 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8342\nEpoch 00007: val_accuracy did not improve from 0.66448\n191/191 [==============================] - 2s 12ms/step - loss: 0.3805 - accuracy: 0.8342 - val_loss: 0.6962 - val_accuracy: 0.6638\nEpoch 8/20\n188/191 [============================>.] - ETA: 0s - loss: 0.3432 - accuracy: 0.8501\nEpoch 00008: val_accuracy improved from 0.66448 to 0.67761, saving model to glove_model.h5\n191/191 [==============================] - 2s 12ms/step - loss: 0.3419 - accuracy: 0.8507 - val_loss: 0.7370 - val_accuracy: 0.6776\nEpoch 9/20\n191/191 [==============================] - ETA: 0s - loss: 0.3116 - accuracy: 0.8714\nEpoch 00009: val_accuracy did not improve from 0.67761\n191/191 [==============================] - 2s 12ms/step - loss: 0.3116 - accuracy: 0.8714 - val_loss: 0.6555 - val_accuracy: 0.6697\nEpoch 10/20\n191/191 [==============================] - ETA: 0s - loss: 0.2687 - accuracy: 0.8905\nEpoch 00010: val_accuracy did not improve from 0.67761\n191/191 [==============================] - 2s 12ms/step - loss: 0.2687 - accuracy: 0.8905 - val_loss: 0.7610 - val_accuracy: 0.6730\nEpoch 11/20\n191/191 [==============================] - ETA: 0s - loss: 0.2414 - accuracy: 0.9034\nEpoch 00011: val_accuracy did not improve from 0.67761\n191/191 [==============================] - 2s 12ms/step - loss: 0.2414 - accuracy: 0.9034 - val_loss: 0.7664 - val_accuracy: 0.6546\nEpoch 12/20\n189/191 [============================>.] - ETA: 0s - loss: 0.2195 - accuracy: 0.9165\nEpoch 00012: val_accuracy did not improve from 0.67761\n191/191 [==============================] - 2s 12ms/step - loss: 0.2186 - accuracy: 0.9171 - val_loss: 0.8956 - val_accuracy: 0.6573\nEpoch 13/20\n190/191 [============================>.] - ETA: 0s - loss: 0.1877 - accuracy: 0.9265\nEpoch 00013: val_accuracy did not improve from 0.67761\n191/191 [==============================] - 2s 12ms/step - loss: 0.1877 - accuracy: 0.9264 - val_loss: 0.9327 - val_accuracy: 0.6435\nEpoch 14/20\n189/191 [============================>.] - ETA: 0s - loss: 0.1691 - accuracy: 0.9370\nEpoch 00014: val_accuracy did not improve from 0.67761\n191/191 [==============================] - 2s 12ms/step - loss: 0.1686 - accuracy: 0.9373 - val_loss: 0.8959 - val_accuracy: 0.6573\nEpoch 15/20\n189/191 [============================>.] - ETA: 0s - loss: 0.1549 - accuracy: 0.9406\nEpoch 00015: val_accuracy did not improve from 0.67761\n191/191 [==============================] - 2s 12ms/step - loss: 0.1543 - accuracy: 0.9409 - val_loss: 1.1850 - val_accuracy: 0.6481\nEpoch 00015: early stopping\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"a7ea4567-4546-4ee8-af44-42b5a1704293"},"source":"","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"deepnote_notebook_id":"a3439b93-7517-4fa6-8fe0-be6b8681a39d","deepnote_execution_queue":[]}}